{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "CNN_Scratch.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-11-18T10:48:00.886824Z",
          "iopub.execute_input": "2021-11-18T10:48:00.887488Z",
          "iopub.status.idle": "2021-11-18T10:48:00.894647Z",
          "shell.execute_reply.started": "2021-11-18T10:48:00.887441Z",
          "shell.execute_reply": "2021-11-18T10:48:00.893467Z"
        },
        "trusted": true,
        "id": "WDExKUouKWhQ"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T11:11:22.862097Z",
          "iopub.execute_input": "2021-11-18T11:11:22.863292Z",
          "iopub.status.idle": "2021-11-18T11:11:22.871544Z",
          "shell.execute_reply.started": "2021-11-18T11:11:22.863239Z",
          "shell.execute_reply": "2021-11-18T11:11:22.870266Z"
        },
        "trusted": true,
        "id": "FcD6iNo_KWhU"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras import models, layers, regularizers, metrics, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#from keras.applications import VGG19\n",
        "from  tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow import keras\n",
        "from scipy import stats\n",
        "import shutil\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrYeNw7mKWhV"
      },
      "source": [
        "## **Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T10:48:07.525534Z",
          "iopub.execute_input": "2021-11-18T10:48:07.525860Z",
          "iopub.status.idle": "2021-11-18T10:48:07.531645Z",
          "shell.execute_reply.started": "2021-11-18T10:48:07.525818Z",
          "shell.execute_reply": "2021-11-18T10:48:07.530623Z"
        },
        "trusted": true,
        "id": "s2S3WNBhKWhX"
      },
      "source": [
        "training_path =  \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/\"\n",
        "test_path =  \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T10:48:07.533316Z",
          "iopub.execute_input": "2021-11-18T10:48:07.534068Z",
          "iopub.status.idle": "2021-11-18T10:48:07.553877Z",
          "shell.execute_reply.started": "2021-11-18T10:48:07.533994Z",
          "shell.execute_reply": "2021-11-18T10:48:07.552496Z"
        },
        "trusted": true,
        "id": "JdgP44wkKWhX"
      },
      "source": [
        "labels = ['MildDemented','ModerateDemented','NonDemented', 'VeryMildDemented'] # labels of dataset (4 classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T10:48:08.369734Z",
          "iopub.execute_input": "2021-11-18T10:48:08.370303Z",
          "iopub.status.idle": "2021-11-18T10:48:08.384047Z",
          "shell.execute_reply.started": "2021-11-18T10:48:08.370262Z",
          "shell.execute_reply": "2021-11-18T10:48:08.382334Z"
        },
        "trusted": true,
        "id": "b0xXv7RDKWhY"
      },
      "source": [
        "# number of images for each folder(class) in train dataset\n",
        "for label in labels:\n",
        "    list = os.listdir(training_path + label) \n",
        "    number_files = len(list)\n",
        "    print(\"the number of images in \" + label +  \" class = \"+ str(number_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T10:48:16.246749Z",
          "iopub.execute_input": "2021-11-18T10:48:16.247502Z",
          "iopub.status.idle": "2021-11-18T10:48:16.661324Z",
          "shell.execute_reply.started": "2021-11-18T10:48:16.247470Z",
          "shell.execute_reply": "2021-11-18T10:48:16.660168Z"
        },
        "trusted": true,
        "id": "35SBfMmkKWhZ"
      },
      "source": [
        "# number of images for each folder(class) in test dataset\n",
        "for label in labels:\n",
        "    list = os.listdir(test_path + label) \n",
        "    number_files = len(list)\n",
        "    print(\"the number of images in \" + label +  \" class = \"+ str(number_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T10:48:23.684604Z",
          "iopub.execute_input": "2021-11-18T10:48:23.685206Z",
          "iopub.status.idle": "2021-11-18T10:48:23.690405Z",
          "shell.execute_reply.started": "2021-11-18T10:48:23.685175Z",
          "shell.execute_reply": "2021-11-18T10:48:23.689056Z"
        },
        "trusted": true,
        "id": "abAzInKhKWhZ"
      },
      "source": [
        "# new pathes for train, validation, test\n",
        "new_training_path   = \"../files/alzheimers-dataset-4-class-of-images/dataset/training_set/\"\n",
        "new_validation_path = \"../files/alzheimers-dataset-4-class-of-images/dataset/validation_set/\"\n",
        "new_test_path       = \"../files/alzheimers-dataset-4-class-of-images/dataset/test_set/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T10:48:30.705731Z",
          "iopub.execute_input": "2021-11-18T10:48:30.706399Z",
          "iopub.status.idle": "2021-11-18T10:48:30.723222Z",
          "shell.execute_reply.started": "2021-11-18T10:48:30.706366Z",
          "shell.execute_reply": "2021-11-18T10:48:30.721776Z"
        },
        "trusted": true,
        "id": "5SXgpbV-KWha"
      },
      "source": [
        "# This module helps in automating the process of copying and removal of files and directories. \n",
        "# shutil.rmtree() is used to delete an entire directory tree, path must point to a directory (but not a symbolic link to a directory).\n",
        "\n",
        "shutil.rmtree(new_training_path, ignore_errors=True)\n",
        "shutil.rmtree(new_validation_path, ignore_errors=True) \n",
        "shutil.rmtree(new_test_path, ignore_errors=True)\n",
        "[os.makedirs(new_training_path + label,exist_ok=True) for label in labels]\n",
        "[os.makedirs(new_validation_path + label,exist_ok=True) for label in labels]\n",
        "[os.makedirs(new_test_path + label,exist_ok=True) for label in labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T10:48:34.719794Z",
          "iopub.execute_input": "2021-11-18T10:48:34.720520Z",
          "iopub.status.idle": "2021-11-18T10:49:12.436614Z",
          "shell.execute_reply.started": "2021-11-18T10:48:34.720471Z",
          "shell.execute_reply": "2021-11-18T10:49:12.435602Z"
        },
        "trusted": true,
        "id": "_yKgSLPSKWhb"
      },
      "source": [
        "# for split train dataset for each class to train and validation within(validation_split = 0.20), make agumentation and upsampling on train dataset\n",
        "validation_split = 0.20\n",
        "training_label_frequencies   = []\n",
        "for label in labels:\n",
        "        training_filenames   = os.listdir(training_path + label + \"/\") \n",
        "        validation_filenames = random.sample(training_filenames, int(len(training_filenames)*validation_split))\n",
        "        training_filenames   = [file for file in training_filenames if file not in validation_filenames]\n",
        "        test_filenames       = os.listdir(test_path + label + \"/\") \n",
        "        for file in training_filenames:\n",
        "            shutil.copy(training_path + label + \"/\" + file, new_training_path + label + \"/\" + file)\n",
        "        print('Training images transfer complete for label: ' + label + '. # transferred images: ' + str(len(training_filenames)))\n",
        "        for file in validation_filenames:\n",
        "            shutil.copy(training_path + label + \"/\" + file, new_validation_path + label + \"/\" + file)\n",
        "        print('Validation images transfer complete for label: ' + label + '. # transferred images: '  + str(len(validation_filenames)))\n",
        "        for file in test_filenames:\n",
        "            shutil.copy(test_path + label + \"/\" + file, new_test_path + label + \"/\" + file)\n",
        "        print('Test images transfer complete for label: ' + label + '. # transferred images: '  + str(len(test_filenames)))\n",
        "        training_label_frequencies.append(len(training_filenames))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T10:51:53.665484Z",
          "iopub.execute_input": "2021-11-18T10:51:53.666034Z",
          "iopub.status.idle": "2021-11-18T10:51:54.553057Z",
          "shell.execute_reply.started": "2021-11-18T10:51:53.665990Z",
          "shell.execute_reply": "2021-11-18T10:51:54.552083Z"
        },
        "trusted": true,
        "id": "57bUwJ4nKWhc"
      },
      "source": [
        "# doing upsampling\n",
        "# training_label_frequencies list of numbers images for each class to train , # [ 574   42 2048 1434]\n",
        "training_label_frequencies = np.array(training_label_frequencies)\n",
        "target_n_samples   = np.max(training_label_frequencies) # large number of images = 2048\n",
        "for i in range(len(labels)):\n",
        "    current_label     = labels[i]\n",
        "    n_missing_samples = target_n_samples - training_label_frequencies[i]  # sub 2048 - (number of images in other classes),With the difference in the subtraction,  make images  in class. \n",
        "    filenames         = os.listdir(new_training_path + current_label + \"/\") \n",
        "    n_filled          = np.zeros(len(filenames))\n",
        "    while (np.sum(n_filled) < n_missing_samples):\n",
        "            idx = np.random.randint(0,len(filenames))\n",
        "            shutil.copy(new_training_path + current_label + \"/\" + filenames[idx], new_training_path + current_label + \"/\" + filenames[idx].replace(\".jpg\", \"_copy_\" + str(int(n_filled[idx] + 1)) + \".jpg\"))\n",
        "            n_filled[idx] += 1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T10:52:01.577009Z",
          "iopub.execute_input": "2021-11-18T10:52:01.577317Z",
          "iopub.status.idle": "2021-11-18T10:52:01.592753Z",
          "shell.execute_reply.started": "2021-11-18T10:52:01.577284Z",
          "shell.execute_reply": "2021-11-18T10:52:01.591269Z"
        },
        "trusted": true,
        "id": "GsqZVY1YKWhc"
      },
      "source": [
        " # number of images for each folder(class) in new_training_path (equal==2048)\n",
        "for label in labels:\n",
        "    list = os.listdir(new_training_path + label) \n",
        "    number_files = len(list)\n",
        "    print(\"the number of images in \" + label +  \" class = \"+ str(number_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T10:52:47.883839Z",
          "iopub.execute_input": "2021-11-18T10:52:47.884241Z",
          "iopub.status.idle": "2021-11-18T10:52:47.892385Z",
          "shell.execute_reply.started": "2021-11-18T10:52:47.884180Z",
          "shell.execute_reply": "2021-11-18T10:52:47.890325Z"
        },
        "trusted": true,
        "id": "7LNXwTjlKWhd"
      },
      "source": [
        "# make agumentation for training data\n",
        "rotation_range      = 0.1\n",
        "width_shift_range   = 0.1\n",
        "height_shift_range  = 0.1\n",
        "shear_range         = 0.1\n",
        "brightness_range    = [0.8,1.2]\n",
        "zoom_range          = 0.1\n",
        "horizontal_flip     = False\n",
        "fill_mode           = 'nearest'\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                         rotation_range     = rotation_range,\n",
        "                                         width_shift_range  = width_shift_range,\n",
        "                                         height_shift_range = height_shift_range,\n",
        "                                         shear_range        = shear_range,\n",
        "                                         brightness_range   = brightness_range,\n",
        "                                         zoom_range         = zoom_range,\n",
        "                                         horizontal_flip    = horizontal_flip,\n",
        "                                         fill_mode          = fill_mode)\n",
        "\n",
        "## or without agumentation \n",
        "#train_datagen   = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T10:52:58.732555Z",
          "iopub.execute_input": "2021-11-18T10:52:58.732954Z",
          "iopub.status.idle": "2021-11-18T10:52:58.738290Z",
          "shell.execute_reply.started": "2021-11-18T10:52:58.732877Z",
          "shell.execute_reply": "2021-11-18T10:52:58.737068Z"
        },
        "trusted": true,
        "id": "Y3TfxSB1KWhd"
      },
      "source": [
        "validation_datagen   = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen         = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T10:54:07.207885Z",
          "iopub.execute_input": "2021-11-18T10:54:07.208312Z",
          "iopub.status.idle": "2021-11-18T10:54:08.177264Z",
          "shell.execute_reply.started": "2021-11-18T10:54:07.208268Z",
          "shell.execute_reply": "2021-11-18T10:54:08.176319Z"
        },
        "trusted": true,
        "id": "RuH-lpaPKWhd"
      },
      "source": [
        "# vgg19 take image with size (224, 224, 3)\n",
        "target_img_shape_1 = 224\n",
        "target_img_shape_2 = 224\n",
        "target_img_channels= 3\n",
        "\n",
        "# batch size 40 , but in report (paper batch size = 20)\n",
        "batch_size = 40\n",
        "\n",
        "train_generator      = train_datagen.flow_from_directory(new_training_path,target_size = (target_img_shape_1, target_img_shape_2), batch_size = batch_size, class_mode = \"categorical\")  \n",
        "validation_generator = validation_datagen.flow_from_directory(new_validation_path,target_size = (target_img_shape_1, target_img_shape_2), batch_size = batch_size, class_mode = \"categorical\") \n",
        "test_generator       = test_datagen.flow_from_directory(new_test_path,target_size = (target_img_shape_1, target_img_shape_2), batch_size = batch_size, class_mode = \"categorical\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYy8egBNKWhe"
      },
      "source": [
        "## **After split +  upsampling + agumentaion on train dataset**\n",
        "making train on  8192 images belonging to 4 classes, \n",
        "validation on    1023 images belonging to 4 classes and \n",
        "test on          1279 images belonging to 4 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T11:00:50.992133Z",
          "iopub.execute_input": "2021-11-18T11:00:50.992402Z",
          "iopub.status.idle": "2021-11-18T11:00:51.001979Z",
          "shell.execute_reply.started": "2021-11-18T11:00:50.992373Z",
          "shell.execute_reply": "2021-11-18T11:00:51.000893Z"
        },
        "trusted": true,
        "id": "H5cT9cTSKWhe"
      },
      "source": [
        "## to display images\n",
        "def display_input_images(generator, max_n_figures, batch_size, grid_size, fig_size):\n",
        "    \n",
        "    fig_counter = 0\n",
        "    for image_batch, label_batch in generator: \n",
        "        plt.figure(figsize=(fig_size[0],fig_size[1]))\n",
        "        for j in range(batch_size):\n",
        "            ax   = plt.subplot(grid_size[0], grid_size[1], j + 1)\n",
        "            plt.imshow(image_batch[j])\n",
        "            if (label_batch[j][0] == 1):\n",
        "                    plt.title('MildDemented')\n",
        "            elif (label_batch[j][1] == 1):\n",
        "                    plt.title('ModerateDemented')\n",
        "            elif (label_batch[j][2] == 1):\n",
        "                    plt.title('NonDemented')\n",
        "            else:\n",
        "                    plt.title('VeryMildDemented')\n",
        "            plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        fig_counter += 1\n",
        "        if (fig_counter == max_n_figures): break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T11:00:58.431720Z",
          "iopub.execute_input": "2021-11-18T11:00:58.432034Z",
          "iopub.status.idle": "2021-11-18T11:01:05.956951Z",
          "shell.execute_reply.started": "2021-11-18T11:00:58.432002Z",
          "shell.execute_reply": "2021-11-18T11:01:05.956118Z"
        },
        "trusted": true,
        "id": "-b5xkV3eKWhe"
      },
      "source": [
        "display_input_images(train_generator, 2, batch_size, [8,5], [30,30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T11:01:15.409570Z",
          "iopub.execute_input": "2021-11-18T11:01:15.410012Z",
          "iopub.status.idle": "2021-11-18T11:01:15.421687Z",
          "shell.execute_reply.started": "2021-11-18T11:01:15.409925Z",
          "shell.execute_reply": "2021-11-18T11:01:15.420499Z"
        },
        "trusted": true,
        "id": "ThSMzE9sKWhf"
      },
      "source": [
        "##  function return information about dataset train, validation, test\n",
        "def dataset_basic_info(generator, name):\n",
        "        print('The ' + name + ' data set includes ' + str(generator.samples) + ' samples.')\n",
        "        print('The ' + name + ' image shapes is ' + str(generator.image_shape))\n",
        "        keys = [el for el in generator.class_indices.keys()]\n",
        "        print('The ' + name + ' data set includes the following labels: ')\n",
        "        print(keys)\n",
        "        labels     = generator.labels\n",
        "        cat_labels = []\n",
        "        for i in range(len(labels)):\n",
        "            for j in range(len(keys)):\n",
        "                if (labels[i] == j):\n",
        "                    cat_labels.append(keys[j])\n",
        "                    break\n",
        "        occurrences = []\n",
        "        for key in keys:\n",
        "            counter = 0\n",
        "            for i in range(len(cat_labels)):\n",
        "                if cat_labels[i] == key:\n",
        "                    counter += 1\n",
        "            occurrences.append(counter)\n",
        "        print(name + ' data set labels frequencies:')\n",
        "        weights = {}\n",
        "        for i in range(len(keys)):\n",
        "            print(keys[i] + ': ' + str(occurrences[i]) + ' (absolute), ' + str(round(occurrences[i]/float(generator.samples), 3)) + ' (relative).' )\n",
        "            weights[i] = generator.samples/np.array(occurrences[i])*(1.0/float(len(keys)))\n",
        "        \n",
        "        return weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T11:01:21.602530Z",
          "iopub.execute_input": "2021-11-18T11:01:21.602831Z",
          "iopub.status.idle": "2021-11-18T11:01:21.707202Z",
          "shell.execute_reply.started": "2021-11-18T11:01:21.602803Z",
          "shell.execute_reply": "2021-11-18T11:01:21.705682Z"
        },
        "trusted": true,
        "id": "WzSrCc2mKWhf"
      },
      "source": [
        "##\n",
        "train_labels_weights_dict      = dataset_basic_info(train_generator, 'training')\n",
        "validation_labels_weights_dict = dataset_basic_info(validation_generator, 'validation')\n",
        "test_labels_weights_dict       = dataset_basic_info(test_generator, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9sR9ID1KWhf"
      },
      "source": [
        "## **implementation modele CNN_ from Scratch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5a9bJuy4KWhg"
      },
      "source": [
        "def build_model_cnn(regression_problem, conv_filters, conv_filter_shape, conv_activation_function, conv_padding, conv_pooling_type, conv_pooling_shape, hidden_layers_neurons, hidden_activation_function, L1_coeffs, L2_coeffs, hidden_layers_dropout, final_layer_neurons, final_activation_function, shape, model_optimizer, loss_function, metrics):\n",
        "    \n",
        "    model = models.Sequential()\n",
        "    \n",
        "    for i in range(len(conv_activation_function)):  #conv_activation_function = ['relu']*conv_layers = 4\n",
        "        \n",
        "        if (i == 0):\n",
        "            model.add(layers.Conv2D(conv_filters[i],\n",
        "                                    (conv_filter_shape[i][0],conv_filter_shape[i][1]), \n",
        "                                    activation = conv_activation_function[i], \n",
        "                                    padding    = conv_padding[i],\n",
        "                                    input_shape = (shape[0],shape[1],shape[2])))             \n",
        "        else:\n",
        "            model.add(layers.Conv2D(conv_filters[i],\n",
        "                                    (conv_filter_shape[i][0],conv_filter_shape[i][1]), \n",
        "                                    activation = conv_activation_function[i],\n",
        "                                    padding    = conv_padding[i]))\n",
        "        \n",
        "        if (conv_pooling_type[i] == 'max'):\n",
        "            model.add(layers.MaxPooling2D((conv_pooling_shape[i][0],conv_pooling_shape[i][1])))\n",
        "        elif (conv_pooling_type[i] == 'avg'):\n",
        "            model.add(layers.AveragePooling2D((conv_pooling_shape[i][0],conv_pooling_shape[i][1])))\n",
        "        else:\n",
        "            'no pooling'\n",
        "            \n",
        "    model.add(layers.Flatten())\n",
        "    \n",
        "    for i in range(len(hidden_activation_function)):\n",
        "\n",
        "        model.add(layers.Dense(hidden_layers_neurons[i], \n",
        "                               kernel_regularizer = regularizers.l1_l2(l1 = L1_coeffs[i], l2 =  L2_coeffs[i]),  \n",
        "                               activation=hidden_activation_function[i]))\n",
        "        if (hidden_layers_dropout[i] > 0.0):\n",
        "            model.add(layers.Dropout(hidden_layers_dropout[i]))\n",
        "    if regression_problem:\n",
        "            model.add(layers.Dense(final_layer_neurons))\n",
        "    else:\n",
        "            model.add(layers.Dense(final_layer_neurons,activation = final_activation_function))\n",
        "            \n",
        "    model.compile(optimizer = model_optimizer, loss = loss_function, metrics = metrics)\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MirrAMHzKWhg"
      },
      "source": [
        "## **parameters of models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T11:03:50.713916Z",
          "iopub.execute_input": "2021-11-18T11:03:50.714184Z",
          "iopub.status.idle": "2021-11-18T11:03:53.676578Z",
          "shell.execute_reply.started": "2021-11-18T11:03:50.714155Z",
          "shell.execute_reply": "2021-11-18T11:03:53.675668Z"
        },
        "trusted": true,
        "id": "VPI2ccfqKWhg"
      },
      "source": [
        "n_epochs                       = 40\n",
        "batch_size                     = 40\n",
        "validation_steps               = 50\n",
        "conv_layers                    = 4\n",
        "conv_filters                   = [32,64,128,128]   \n",
        "conv_filter_shape              = [[3,3]]*conv_layers\n",
        "conv_activation_function       = ['relu']*conv_layers\n",
        "conv_padding                   = ['valid']*conv_layers\n",
        "conv_pooling_type              = ['max']*conv_layers\n",
        "conv_pooling_shape             = [[2,2]]*conv_layers\n",
        "regression_problem             = False\n",
        "print_sample_input             = True\n",
        "hidden_activation_function     = ['relu']\n",
        "hidden_layers_neurons          = [128]\n",
        "hidden_layers_L1_coeffs        = [0.00]\n",
        "hidden_layers_L2_coeffs        = [0.00]\n",
        "hidden_layers_dropout          = [0.00]\n",
        "final_activation_function      = 'softmax'\n",
        "final_layer_neurons            = 4\n",
        "model_optimizer                = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "loss_function                  = 'categorical_crossentropy'\n",
        "metrics                        = [ keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
        "                                   keras.metrics.AUC(multi_label = True, name='multiclass_AUC')]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "orcizTPcKWhh"
      },
      "source": [
        "model = build_model_cnn(regression_problem, conv_filters, conv_filter_shape, conv_activation_function, conv_padding, conv_pooling_type, conv_pooling_shape, hidden_layers_neurons, hidden_activation_function, \n",
        "                             hidden_layers_L1_coeffs, hidden_layers_L2_coeffs, hidden_layers_dropout, final_layer_neurons, final_activation_function, [target_img_shape_1, target_img_shape_2, target_img_channels], \n",
        "                             model_optimizer, loss_function, metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T11:11:41.299410Z",
          "iopub.execute_input": "2021-11-18T11:11:41.299670Z",
          "iopub.status.idle": "2021-11-18T11:11:42.259975Z",
          "shell.execute_reply.started": "2021-11-18T11:11:41.299641Z",
          "shell.execute_reply": "2021-11-18T11:11:42.258912Z"
        },
        "trusted": true,
        "id": "ZgokTYMwKWhh"
      },
      "source": [
        "## plot model\n",
        "tensorflow.keras.utils.plot_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuyZzCerKWhi"
      },
      "source": [
        "## **fit model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T11:22:02.491061Z",
          "iopub.execute_input": "2021-11-18T11:22:02.491480Z",
          "iopub.status.idle": "2021-11-18T12:45:06.016968Z",
          "shell.execute_reply.started": "2021-11-18T11:22:02.491411Z",
          "shell.execute_reply": "2021-11-18T12:45:06.015954Z"
        },
        "trusted": true,
        "id": "nZZ2s6DpKWhi"
      },
      "source": [
        "early_exit      = EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='min')\n",
        "best_checkpoint = ModelCheckpoint('best_fit.h5', save_best_only=True, monitor='val_multiclass_AUC', mode='max')\n",
        "\n",
        "hst = model.fit(train_generator, steps_per_epoch = train_generator.samples//batch_size, epochs = n_epochs, validation_data = validation_generator, validation_steps = validation_generator.samples//batch_size, callbacks =[early_exit, best_checkpoint])\n",
        "        \n",
        "model.load_weights(filepath = 'best_fit.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T12:46:35.874401Z",
          "iopub.execute_input": "2021-11-18T12:46:35.874703Z",
          "iopub.status.idle": "2021-11-18T12:46:35.888372Z",
          "shell.execute_reply.started": "2021-11-18T12:46:35.874657Z",
          "shell.execute_reply": "2021-11-18T12:46:35.887084Z"
        },
        "trusted": true,
        "id": "SeSnQcPYKWhj"
      },
      "source": [
        "## categorical_accuracy, These metrics are used for classification problems involving more than two classes.\n",
        "## categorical_accuracy metric computes the mean accuracy rate across all predictions.\n",
        "## the area under the ROC curve (AUC) ,\n",
        "## The Area Under the Curve (AUC) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of the ROC curve. \n",
        "## The higher the AUC, the better the performance of the model at distinguishing between the positive and negative classes\n",
        "## For multiclass problems, ROC curves can be plotted with the methodology of using one class versus the rest. \n",
        "## Use this one-versus-rest for each class and you will have the same number of curves as classes. The AUC score can also be calculated for each class individually\n",
        "\n",
        "\n",
        "def analyze_performances(hst, epochs):\n",
        "    history_dict             = hst.history\n",
        "    loss_values              = history_dict['loss']\n",
        "    validation_loss_values   = history_dict['val_loss']\n",
        "    acc_values               = history_dict['categorical_accuracy']\n",
        "    validation_acc_values    = history_dict['val_categorical_accuracy']\n",
        "    auc_values               = history_dict['multiclass_AUC']\n",
        "    validation_auc_values    = history_dict['val_multiclass_AUC']\n",
        "    epochs                   = range(1,len(loss_values) + 1)\n",
        "    fig, axes                = plt.subplots(1,3,figsize = (30,10))\n",
        "    training_ts              = [loss_values, acc_values, auc_values]\n",
        "    validation_ts            = [validation_loss_values, validation_acc_values, validation_auc_values]\n",
        "    metric_names             = ['loss', 'categorical accuracy','average multiclass AUC']\n",
        "    for i in range(len(axes)):\n",
        "        axes[i].plot(epochs,training_ts[i],color = 'r',label = 'training')\n",
        "        axes[i].plot(epochs,validation_ts[i],color = 'b',label = 'validation')\n",
        "        axes[i].set_xlabel('epoch')\n",
        "        axes[i].set_ylabel(metric_names[i])\n",
        "        axes[i].set_title(metric_names[i] + ' analysis')\n",
        "        axes[i].set_xticks(np.arange(0,epochs[-1] + 1,5))\n",
        "        axes[i].set_yticks(np.arange(0,1.1,0.1))\n",
        "        axes[i].set_xlim([1,epochs[-1]])\n",
        "        axes[i].set_ylim([np.min([np.min(training_ts[i]),np.min(validation_ts[i])]),np.max([np.max(training_ts[i]),np.max(validation_ts[i])])])\n",
        "        axes[i].legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T12:46:41.675320Z",
          "iopub.execute_input": "2021-11-18T12:46:41.676354Z",
          "iopub.status.idle": "2021-11-18T12:46:42.268805Z",
          "shell.execute_reply.started": "2021-11-18T12:46:41.676301Z",
          "shell.execute_reply": "2021-11-18T12:46:42.267789Z"
        },
        "trusted": true,
        "id": "Z96r64XnKWhj"
      },
      "source": [
        "analyze_performances(hst, n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tXYQ9X9KWhj"
      },
      "source": [
        "## **Evaluate** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T12:49:42.496864Z",
          "iopub.execute_input": "2021-11-18T12:49:42.497798Z",
          "iopub.status.idle": "2021-11-18T12:49:42.516669Z",
          "shell.execute_reply.started": "2021-11-18T12:49:42.497740Z",
          "shell.execute_reply": "2021-11-18T12:49:42.515684Z"
        },
        "trusted": true,
        "id": "7U8Ofgo6KWhj"
      },
      "source": [
        "## \n",
        "def model_evaluation(model, test_generator):\n",
        "    test_loss_1, test_acc_1, test_auc_1 = model.evaluate_generator(test_generator, verbose=0)\n",
        "    print('The value of the loss function on the test data set is: ' + str(round(test_loss_1,4)))\n",
        "    print('The categorical accuracy of the predictions on the test data set is: ' + str(round(test_acc_1,4)))\n",
        "    print('The categorical AUC (i.e., average curve across classes) of the predictions on the test data set is: ' + str(round(test_auc_1,4)))\n",
        "    \n",
        "    class_labels = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented'] #list(test_generator.class_indices.keys())\n",
        "    predictions = []\n",
        "    true        = []\n",
        "    ctr         = 0\n",
        "    for batch, label in test_generator:\n",
        "        prediction = model.predict(batch).argmax(axis = -1)\n",
        "        predictions.extend(prediction)\n",
        "        true.extend(label.argmax(axis = -1))\n",
        "        ctr += len(prediction)\n",
        "        if ctr >= len(test_generator.labels):\n",
        "            break\n",
        "            \n",
        "    matrix     = confusion_matrix(true,predictions)\n",
        "    rel_matrix = matrix/np.sum(matrix,axis = 0)\n",
        "    fig, axes  = plt.subplots(1,2,figsize = (20,40))\n",
        "\n",
        "    image1 = axes[0].imshow(matrix, cmap=plt.get_cmap('GnBu'))\n",
        "    for (i, j), e in np.ndenumerate(matrix):\n",
        "        axes[0].text(j, i, s = str(e), ha='center', va='center')\n",
        "    axes[0].set_xticks(np.arange(0,len(class_labels), 1))\n",
        "    axes[0].set_xticklabels(class_labels)\n",
        "    axes[0].set_yticks(np.arange(0,len(class_labels), 1))\n",
        "    axes[0].set_yticklabels(class_labels)\n",
        "    axes[0].set_title('Confusion Matrix')\n",
        "    \n",
        "    image2 = axes[1].imshow(matrix/np.sum(matrix,axis = 0), cmap=plt.get_cmap('GnBu'))\n",
        "    for (i, j), e in np.ndenumerate(rel_matrix):\n",
        "        axes[1].text(j, i, s = str(np.round(e,2)), ha='center', va='center')\n",
        "    axes[1].set_xticks(np.arange(0,len(class_labels), 1))\n",
        "    axes[1].set_xticklabels(class_labels)\n",
        "    axes[1].set_yticks(np.arange(0,len(class_labels), 1))\n",
        "    axes[1].set_yticklabels(class_labels)\n",
        "    plt.subplots_adjust(wspace = 0.5)\n",
        "    axes[1].set_title('Confusion Matrix (Relative)')                      \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T12:49:51.162740Z",
          "iopub.execute_input": "2021-11-18T12:49:51.163219Z",
          "iopub.status.idle": "2021-11-18T12:49:57.015368Z",
          "shell.execute_reply.started": "2021-11-18T12:49:51.163184Z",
          "shell.execute_reply": "2021-11-18T12:49:57.014419Z"
        },
        "trusted": true,
        "id": "eLdufsHdKWhk"
      },
      "source": [
        "model_evaluation(model, test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-18T12:48:55.427063Z",
          "iopub.execute_input": "2021-11-18T12:48:55.427353Z",
          "iopub.status.idle": "2021-11-18T12:48:55.434815Z",
          "shell.execute_reply.started": "2021-11-18T12:48:55.427318Z",
          "shell.execute_reply": "2021-11-18T12:48:55.433523Z"
        },
        "trusted": true,
        "id": "jIqOE1iUKWhk"
      },
      "source": [
        "test_generator.class_indices.keys()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}